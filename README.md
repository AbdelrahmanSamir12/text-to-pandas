# text-to-pandas

fine-tuned BART model to generate executable pandas code from natural language questions on tabular data.

---

## ğŸš€ Overview

**text-to-pandas** converts schema-rich natural language prompts into executable pandas expressions. It uses a BART sequence-to-sequence model, fine-tuned on a dataset of table schemas and associated queries.

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ data
â”‚ â”œâ”€â”€ external/
â”‚ â”œâ”€â”€ interim/
â”‚ â”œâ”€â”€ processed/
â”‚ â”‚ â”œâ”€â”€ test_clean.csv
â”‚ â”‚ â””â”€â”€ train_clean.csv
â”‚ â””â”€â”€ raw/
â”‚ â”œâ”€â”€ test.csv
â”‚ â””â”€â”€ train.csv
â”œâ”€â”€ docs/
â”œâ”€â”€ models/
â”‚ â””â”€â”€ text-to-pandas-bart/
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ data_exploration.ipynb
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ references/
â”œâ”€â”€ reports/
â”‚ â””â”€â”€ figures/
â”œâ”€â”€ results/
â”‚ â””â”€â”€ eval_predictions.csv
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_downloader.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ test_model.py
â”‚ â””â”€â”€ train.py
â””â”€â”€ uv.lock
```

---

## ğŸ“ Data

Data is sourced from [Hugging Face: Rahima411/text-to-pandas](https://huggingface.co/datasets/Rahima411/text-to-pandas) and preprocessed.

- Raw: `data/raw/`
- Cleaned: `data/processed/`

Each entry gives a table schema, a natural language question, and the correct pandas query.

---

## ğŸ› ï¸ Tech Stack

- **Python** â€“ Core language and scripting
- **uv** â€“ Super-fast Python package & workflow manager [astral-sh/uv](https://github.com/astral-sh/uv)
- **Hugging Face ğŸ¤— Transformers** â€“ For BART model and tokenization
- **PyTorch** â€“ Deep learning backend for model training/inference
- **pandas** â€“ Data manipulation and evaluation
- **Hugging Face Datasets** â€“ Data loading and preprocessing
- **Jupyter Notebooks** â€“ For data exploration and quick prototyping
- **Structured project layout** inspired by Cookiecutter Data Science
---

## ğŸ“š License
MIT License